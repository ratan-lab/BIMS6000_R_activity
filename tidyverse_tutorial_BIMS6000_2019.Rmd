---
title: "BIMS 6000 R Tutorial 2018"
author: Olivia Sabik
output: html_notebook
---

# I. Introduction to R and RStudio

Welcome to R, more specifically, to RStudio. Let me give you an introduction to your surroundings. 

RStudio has four distinct windows:

(1) The first is the scripting section. That's where this text is, and where any script that you write will go. You can save what you write here and open it and run it again later. To submit a line from the script, you can use the keyboard shortcut 'ctrl + enter' on a PC or 'command + enter' on a mac, when your cursor is on that line. 

(2) When you submit a line of code it gets entered into the console, and the computation is run. If the code you put in console returns an output, it will show up in the console. 

(3) The environment section is where all of the objects you create and work on will go. For example, if you read in a data table, you can give it a name, and you can see that it's saved in the environment--then, if you use its name in the future, you can manipulate it. 

(4) The final section contains a few elements. First is the Files tab, which will show you which files are in your working directory, and where you can navigate to and set your working directory by clicking on the blue gear/"More" button. You can read files in, or write out files to your working directory. Second is the Plots tab, which is where any plots you generate will show up and can be exported from. This is usually my active tab when I'm using RStudio and producing plots. Next is the Packages tab, which will list all of your installed packages. Then comes the help tab, where you can search packages and commands and learn more about how to use them. Finally, the Viewer, which can be used for analyses that are outside of the scope of this tutorial. 

# II. Preparing RStudio to do Analyses and Reading in Your Data  

## 1. Dependencies, aka the administative stuff
In order for your script to run, you need to tell RStudio where to look for your files, and that place is called your working directory. You can change the working directory like so:

(Note: Here, (username) is a placeholder. Change it to the appropriate username on your device!)

```{r}
setwd("/Users/(username)/Desktop/")
```

if you are using a PC, the path will look something like this:
```{r}
setwd("C:\Users\(username)\Desktop")
```

Of course this path doesn't exist on your computer, so try changing that path to your own desktop. To do so, just start with setwd("/") and with your cursor after the backslash, hit the TAB button. This will let you see all the directories available to you. You can also go to the files tab and set your working directory there.

We'll also need to install whatever packages we want to use. R comes with some built in features, but the beauty of R is that there are tons of researchers who are actively developing software that you can use to do your work in R. installing packages is super easy. Here is an example:

```{r}
install.packages('tidyverse')
```

After installing these packages, we need to load them up into R, so we can use them right now. You only ever need to install a package once in R, but you need to load it each time. Here's an example of how to load up your packages:

```{r}
library(tidyverse)

sessionInfo()
```

If you don't get any output from the library(package) statement, it means everything is going well. Sometimes you'll get some output, loading statements and such, but as long as you don't see any errors, we should be good to go. So now we have everything set up, let's pull in the most important piece of the puzzle, your data. 

## 2. Objects, aka your data
In order to analyze you data in R, you need to be able to load your data into R, and you need to know how to refer to it. So, let's read in some and give it a name. In this example, suppose you are in your working directory and it contains a tab-delimited file named oncotype.intermediate.tsv, the following code would read that in:

```{r}
dat = read_tsv("PCa_expression_data.tsv")
```
This file is subset of the data from a manuscript on biorxiv (https://www.biorxiv.org/content/10.1101/604058v1.full) Basically we are looking at expression values for genes from a diagnostic panel that is great at prediction of recurrence of prostate cancer in European populations, and we want to test if the expression of those genes in African Americans is similar, because if it isn't, then it might not perform as well.

We can rename our data to something more informative
```{r}
exp_data = dat
```

When we run this line of code, we see a new object appear in our enivornment, called exp_data. What does df look like? Click on it in your environment box. A command should be run in the console that says View(exp_data), and you should see something that looks similar to an excel spreadsheet. Now we can just type in exp_data and R will know we are talking about this specific data. When we read in the expression data, it reads in as dataframe, but we're going to convert it to a tibble, which is very similar to a dataframe, but is the format required for the packages we're going to use later. 

```{r}
exp_data = as_tibble(exp_data)
exp_data
```
Aside: We'll talk about this in a bit more depth later, but %>% is a TidyVerse operator called "pipe". Pipe takes the output of the expression preceding it, and applies the subsequent function to it.

Typically, our data is so large that looking at it as a spreadsheet isn't very useful. So how can we look at and manipulate our data? By using functions.

## 3. Functions, aka how you do things with/to your data

Now that we have what is essentially your excel spreadsheet in RStudio, let's figure out how to use functions to look at our data frame:

### (1) How big is our data frame?
```{r}
dim(exp_data)
```
The output tells us how many rows and columns this data contains

### (2) What does our data frame look like?
```{r}
head(exp_data)

```

You can also use tail() to look at the bottom part of the data

### (3) How are the columns named? 
```{r}
colnames(exp_data)
```

### (5) I'm curious about these columns. Can I find out what is in them easily? 
```{r}
exp_data$Race
table(exp_data$Race)
```

## 4. Comments
The final piece of any good script in R are comments. Comments have a '#' at the front of the line, and their purpose is to help you remember why you did things. When you are in the middle of analyzing your data, everything you are doing will seem so clear, but two months later when you're writing a methods section, you'll thank past you for writing really descriptive comments, that can help guide you through the code. For example:

```{r}
### This is a comment, just to remind myself what I was up to. This command will summarize each column. For numeric data, this will output the minimum value, the maxiumum value, and the 1st and 3rd quartiles. 
summary(exp_data)
```

# III. Analyzing your data:

So now we have our data in RStudio, we know what it looks like, but how can we analyze it? How do we gain insight from this huge data set?

Well we can start by manipulating our data so we can draw comparisons. There are many ways to manipulate or "munge" your data, but we think the most efficient tool to learn first is one called dplyr. In the intro, we installed and libraried tidyverse, which contains dplyr, so now we can use it. 

To start, go to the files/plots/packages/etc. square and click on the packages tab. Then scroll down and click on the link for dplyr. This page shows you all of the functions available in dplyr. Click on any of these links to get information on how to use these functions. We're going to cover 5 basic functions from dplyr, because these 5 functions will cover a lot of what you need for basic data wrangling. 

## (1) select
The select function allows you to essentially cut out just the specific columns you want to use. Let's look at an example. In our data, we have the following columns:

```{r}
colnames(exp_data)
```

Say we are specifically interested in the COL1A1 expression compared to the race of the sample, we can simply use select to choose only those two columns of our data. The select function only needs to know the name of the tibble, in this case it's exp_data, and the names of the columns that we want in our output: ID, Race and COL1A1 

```{r}
select(.data = exp_data, ID, Race, COL1A1)
```

Say we just want to remove one column as opposed to selecting all of the other columns. We can use select, but use the negative sign in front of one column name to remove it. 

```{r}
#output the tibble without the AZPG1 column
select(exp_data, -AZGP1)
```

## (2) filter
The filter function allows us to choose certain rows from the tibble, based on some sort of filtering criterion. Filter needs to know two things; The first is the name of the tibble, again, exp_data. The second is the filter parameter. The filter parameter is just a statement about the value of the column. You have the following basic options: 
(1) == means that the value must exactly equal the chosen value
(2) != means that the value can be anything but the chosen value (essentially (!)not (=)equal to)
(3) you can use < and <= for less than or less than or equal to
(4) and > >= for greater than and greater than or equal to. 

Let's look at some examples:

For example, in our data, we may want to know only about AAM data.

```{r}
filter(exp_data, Race == "AAM")
```

Maybe we only want datapoints where TPM2 is at least 13

```{r}
filter(exp_data, TPM2 >= 13)
```

## (3) mutate
The mutate function allows you to make a new column in your data frame based on an existing one. Mutate needs to know the name of the data frame you're taking data from and adding to, the name of the new column you're adding, and the value of that column.

For example, lets use mutate to log transform AZGP1 expression. 

```{r}
mutate(exp_data, AZGP1_log = log10(AZGP1))
```

## (4) group_by
The group_by function allows you to group the rows based on the values in a particular column. For example, say you want to compare expression by race

```{r}
group_by(exp_data, CAPRASgroup)
```

The results of group_by aren't inherently useful, they don't reorder the table, but they add a layer of organization that can be used by other functions. In just a minute we'll start stacking these together to more interesting manipulations. 

## (5) summarize
The summarize function takes a tibble and summarizes it, but it won't summarize the whole thing; it needs you to group_by one of the variables and it will summarize each group--however you want to analyze them. So how do we stack two steps together? There's a symbol called a pipe, or %>%. This takes the output of one line, and sticks it into another function. 

Let's look at an example:

```{r}
exp_data %>%
  group_by(CAPRASgroup) %>%
  summarize(median(S1PR4))
```

So the pipe takes the data from line one, and sends it into the group_by function, where we add in the CAPRA-S group option to group by, and then takes the grouped data  and puts it into summarize, where we put in one more parameter, that we want to calculate the median expression of S1PR4. The output iis the median of S1PR4 expression for each group. But usually we don't want just one function and one variable to be summarized. 

We can use summarize_at, and the funs() option to do a few functions on a few variables. 

```{r}
exp_data %>%
  group_by(CAPRASgroup) %>%
  summarize_at(vars(S1PR4, COL1A1), funs(min, mean, max))
```

# IV. Plotting your data:
So we got a ton of data, and we want to see what it looks like. While there are built in packages that can do this for you, the package ggplot2 is one such R package for making publication quality plots. 

What does ggplot2 need to know to make your plot?

The first step is to tell ggplot the name of the data frame your data is coming from, and you need to tell it the "aesthetics" you want, so tell it what you want along the x axis, and what you want on the y axis. Then we save that all to an object, which I called "g". Here's a sort of template for what that looks like:

g = ggplot("name of data frame here", aes("x variable column name here","y variable column name here"))

So what can we plot in our example data frame? We can see our options by viewing the column names of our data frame.
```{r}
colnames(exp_data)
```

Let's have ggplot make a plot of COL1A1 vs S1PR4 expression 

```{r}
g = ggplot(exp_data, aes(S1PR4,COL1A1))
```

So we typed that in, but what actually happened? Nothing came out in the console, but our g object did show up in our environment. Let's try to look at it.

```{r}
g 
```

Well that looks like the plot we want to make, but there's nothing on it. That's because we need to add something called a layer. So we have the ggplot function, with the aes inside that tells the program what the x and y axes should be, and then there's the "geom" component, and that is how we will indicate what we want the data to look like on the plot. And we've given you a cheat sheet for how to choose various types of "geoms". The options are ones you're familiar with, like geom_point will give you a scatter plot, and geom_boxplot will give you a box plot. Let's add a geom_point layer to our graph so we can see the data. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(S1PR4,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point()
### Finally, we look at the plot!
g
```

Now we can tell that there's a correlation between the the two genes. But what if we want to fit a line to this data, just to visualize the trend? We can add a layer called geom_smooth, just like geom_point, and looking at the plot, we can try to fit a linear model, so we tell geom_smooth that it should use method = lm, for linear model. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(S1PR4,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point() + geom_smooth(method = lm)
### Finally, we look at the plot!
g
```

Let's try it again, but this time with different variables. Let's look at the relationship between race and COL1A1 expression. Let's just plug it in to the last command we used. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point()
### Finally, we look at the plot!
g
```

Well that's not quite what we want... Clearly the wrong geom. With one discrete variable and one continuous variable, we should plot this as a box_plot. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot()
### Finally, we look at the plot!
g
```

The boxplot is nice, but what if we want to know more about the specific data points, and also have our boxplot? Just add another layer to the plot.

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot() + geom_point()
### Finally, we look at the plot!
g
```

Finally, let's clean up the labels, so everyone who looks at it knows what it represents!
```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot() + geom_point()
### Next, let's change the axes
g = g + xlab("Sample Race") + ylab("COL1A1 expression")
### Finally, we look at the plot!
g
```
These are just some basic plots we can make using ggplots. and if you want to do more with your ggplot, the easiest way to figure out how to do it is to google what you want to do. For example, just type in "color the points by a certain column in ggplot2", or "changing the x and y axis titles in ggplot2". One of the top three hits will likely be an in depth tutorial that can help you build whatever plot you want. 

# V. One Final Example

So let's play around with some of our data using dplyr and then plot it.

Question: In patients with High CAPRA-S risk, does the median expression of COL1A1 differ based on race?

To go about answering this question, we can break it down into steps:
 # start with our whole data frame  
 # filter out our results to get high CAPRA-S risk group (CAPRASgroup == "HIGH")  
 # now plot the COL1A1
 # add the geom layer   
 # add axis labels   
```{r, echo=TRUE}
exp_data %>% 
  filter(CAPRASgroup == "HIGH") %>% 
  ggplot(aes(Race, COL1A1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x="Race", y="COL1A1 expression - High CAPRA-S")
```
Ok, this is cool, but what if we want to compare all CAPRA-S groups at the same time?
We can use facets. Facets allow us to form panels in our plots.
In the following example, we supply CAPRA-S groups as variables for faceting. Each facet will display the data for one CAPRA-S group "variable"


```{r}
exp_data %>% 
  ggplot(aes(Race, COL1A1)) + 
  geom_boxplot() + 
  geom_point() +
  facet_grid(cols = vars(CAPRASgroup))+
  labs(x="Race", y="COL1A1 expression - High CAPRA-S")
```
If you want to explore more of the options you have with ggplot2, refer to the cheat sheet we distributed as well. You can also always find that sheet by googling ggplot2 cheat sheet. 

# VI. One Last Thing: Statistics
We would be remiss if we taught you about R and did not mention that you can use it to do statistical analysis on your data as well. 

Remember the example above, where we plotted COL1A1 and S1PR4 expression? We added a line to the data to look at the relationship between the two variables, but what if we actually wanted to use that line to be able to predict expression of COL1A1 based on S1PR4 expression. We would need a formula. And the command if pretty easy, its just lm() for linear model. 
```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(S1PR4,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point() + geom_smooth(method = lm)
### Finally, we look at the plot!
g
### To calculate the equation of the line:
lm(COL1A1~S1PR4, exp_data)

### So we now know that the relationship between mpg and wt is 
###COL1A1 = 0.4027*S1PR4 + 8.8656 
```

One other common statistical test you may want to use is a t test, to compare two groups of measurements. We can look at the difference between S1PR4 expression for AAM and EAM.
```{r}
# We want to know if y (S1PR4) differs by x(Race)
# Null hypothesis: equal means between populations
t.test(S1PR4~Race, exp_data)

# There is a significant difference in S1PR4 expression between races, can we plot that as well?
g = ggplot(exp_data, aes(Race,S1PR4)) +
  geom_boxplot() +
  geom_point()
g

```

I hope this tutorial was a helpful introduction to RStudio, dplyr, and ggplots. If you want to learn more, there are a lot of classes available from the Stat Lab and Bioconnector at the Health Science Library. All of these resources take what we just presented and help you to build on them.

## RESOURCES

### R Studio Online Learning
https://www.rstudio.com/online-learning/

### STATLAB COURSES
http://data.library.virginia.edu/training/
Fall 2018 dates posted now!

### BIOCONNECTOR COURSES
http://cal.hsl.virginia.edu/calendar/bioconnector?cid=5619&t=d&d=0000-00-00&cal%5B%5D=5619
Fall 2018 posted now!

### STATISTICS RESOURCE
An Introduction to Statistical Learning
https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf

## CONTACT INFO

Dr. Aakrosh Ratan
ar7jq at virginia dot edu

Dr. Charles Farber
crf2s at virginia dot edu

Basel Al-Barghouthi
bma8ne at virginia dot edu




