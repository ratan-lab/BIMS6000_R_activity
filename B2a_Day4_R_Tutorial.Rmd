---
title: "BIMS 6000 R Tutorial 2020"
author: Aakrosh Ratan
output: html_notebook
---
# I. Introduction to R and RStudio

Welcome to R, more specifically, to RStudio. Let me give you an introduction to your surroundings. 

RStudio has four distinct windows:

(1) The first is the scripting section. That's where this text is, and where any script that you write will go. You can save what you write here and open it and run it again later. To submit a line from the script, you can use the keyboard shortcut 'ctrl + enter' on a PC or 'command + enter' on a mac, when your cursor is on that line. 

(2) When you submit a line of code it gets entered into the console, and the computation is run. If the code you put in console returns an output, it will show up in the console. 

(3) The environment section is where all of the objects you create and work on will go. For example, if you read in a data table (like a spreadsheet), you can give it a name, and you can see that it's saved in the environment--then, if you use its name in the future, you can manipulate it. 

(4) The final section contains a few elements. First is the Files tab, which will show you which files are in your working directory, and where you can navigate to and set your working directory by clicking on the blue gear/"More" button. You can read files in, or write out files to your working directory. Second is the Plots tab, which is where any plots you generate will show up and can be exported from. This is usually my active tab when I'm using RStudio and producing plots. Next is the Packages tab, which will list all of your installed packages. Then comes the help tab, where you can search packages and commands and learn more about how to use them. Finally, the Viewer, which can be used for analyses that are outside of the scope of this tutorial. 

# II. Preparing RStudio to do Analyses and Reading in Your Data  

## 1. Dependencies, aka the administative stuff
In order for your script to run, you need to tell RStudio where to look for your files, and that place is called your working directory. You can change the working directory like so:

(Note: Here, (username) is a placeholder. Change it to the appropriate username on your device!)

```{r}
setwd("/Users/(username)/Desktop/")
```

if you are using a PC, the path will look something like this:
```{r}
setwd("C:\Users\(username)\Desktop")
```

Of course this path doesn't exist on your computer, so try changing that path to your own desktop. To do so, just start with setwd("/") and with your cursor after the backslash, hit the TAB button. This will let you see all the directories available to you. You can also go to the files tab and set your working directory there.

We'll also need to install whatever packages we want to use. R comes with some built in features, but the beauty of R is that there are tons of researchers who are actively developing software that you can use to do your work in R. Here is an example of how we install packages:

```{r}
install.packages('tidyverse')
```

After installing these packages, we need to load them up into R, so we can use them right now. You only ever need to install a package once in R, but you need to load it each time. Here's an example of how to load up your packages:

```{r}
library(tidyverse)
```

If you don't get any output from the library(package) statement, it means everything is going well. Sometimes you'll get some output, loading statements and such, but as long as you don't see any errors, we should be good to go. If at any moment you want to see which packages are loaded, you can do the following:

```{r}
sessionInfo()
```
So now we have everything set up, let's pull in the most important piece of the puzzle, your data. 

## 2. Objects, aka your data
In order to analyze you data in R, you need to be able to load your data into R, and you need to know how to refer to it. So, let's read in some and give it a name. In this example, suppose you are in your working directory and it contains a tab-delimited file named `PCa_expression_data.tsv`, the following code would read that in:

```{r}
data = read_tsv("PCa_expression_data.tsv")
```

This file is subset of the data from a manuscript on biorxiv (https://www.biorxiv.org/content/10.1101/604058v1.full). Today, we will look at normalized expression values of genes from a diagnostic panel that is currently used to determine Prostate cancer (PCa) prognosis in men with low or favorable intermediate risk disease. Some data suggests the tests may provide inconsistent risk estimates in the presence of multifocal disease. But the data you will look at will be used to explore if the expression values for genes are different in African American men compared to European American men. Caution needs to be excercised in clinical decision making, and the risk scores determined from these tests need to be re-evaluated if there are statistically significant differences between the expression based on ancestry.

`read_tsv` reads in the values from the file into what is called a `tibble`.

We can rename our data to something more informative
```{r}
exp_data = data
```

When we run this line of code, we see a new object appear in our environment, called exp_data. What does exp_data look like? Click on it in your environment box. A command should be run in the console that says View(exp_data), and you should see something that looks similar to an excel spreadsheet. Now we can just type in exp_data and R will know we are talking about this specific data. 

A note: We'll talk about this in a bit more depth later, but %>% is a Tidyverse operator called "pipe". Pipe takes the output of the expression preceding it, and applies the subsequent function to it.

Typically, our data is so large that looking at it as a spreadsheet isn't very useful. So how can we look at and manipulate our data? By using functions.

## 3. Functions, aka how you do things with/to your data

Now that we have what is essentially your excel spreadsheet in RStudio, let's figure out how to use functions to look at our tibble:

### (1) How big is our tibble?
```{r}
dim(exp_data)
```
The output tells us how many rows and columns this data contains

### (2) What does our tibble look like?
```{r}
head(exp_data,n = 10)
```

You can also use tail() to look at the bottom part of the data. Try it out.

### (3) How are the columns named? 
```{r}
colnames(exp_data)
```

### (5) I'm curious about these columns. Can I find out what is in them easily? 
```{r}
exp_data$Race
```

```{r}
table(exp_data$Race)
```

## 4. Comments
The final piece of any good script in R are comments. Comments have a '#' at the front of the line, and their purpose is to help you remember why you did things. When you are in the middle of analyzing your data, everything you are doing will seem so clear, but two months later when you're writing a methods section, you'll thank past you for writing really descriptive comments, that can help guide you through the code. For example:

```{r}
### This is a comment, just to remind myself what I was up to. This command will summarize each column. For numeric data, this will output the minimum value, the maxiumum value, and the 1st and 3rd quartiles. 
summary(exp_data$COL1A1)
```

# III. Analyzing your data:

So now we have our data in RStudio, we know what it looks like, but how can we analyze it? How do we gain insight from this huge data set?

Well we can start by manipulating our data so we can draw comparisons. There are many ways to manipulate or "munge" your data, but we think the most efficient tool to learn first is one called dplyr. In the intro, we installed tidyverse, which contains dplyr, so now we can use it. 

To start, go to the files/plots/packages/etc. square and click on the packages tab. Then scroll down and click on the link for dplyr. This page shows you all of the functions available in dplyr. Click on any of these links to get information on how to use these functions. We're going to cover 5 basic functions from dplyr, because these 5 functions will cover a lot of what you need for basic data wrangling. 

## (1) select
The select function allows you to essentially subset the specific columns you want to use. Let's look at an example. In our data, we have the following columns:

```{r}
colnames(exp_data)
```

Say we are specifically interested in the COL1A1 expression and the race of the sample. We can simply use select to choose only those two columns of our data. The select function only needs to know the name of the tibble, in this case it's exp_data, and the names of the columns that we want in our output: ID, Race and COL1A1 

```{r}
select(.data = exp_data, ID, Race, COL1A1)

```

Another way to accomplish the same would be to use the %>% operator. 
```{r}
exp_data %>% select(ID, Race, COL1A1)
```

The way to think about this is that you started out with your tibble, and you applied the 'select' function on it to limit the output to a few columns. See how if you do not specify `.data = exp_data` the function assumes that the input is coming from the expression preceding the pipe.

Say we just want to remove one column as opposed to selecting all of the other columns. We can use select, but use the negative sign in front of one column name to remove it. 

```{r}
#output the tibble without the AZPG1 column
select(exp_data, -AZGP1)
```
Again, try using the %>% to accomplish the same as above.

There are several other ways to select columns, for example by specifying indices of the columns instead of the column names. You can also use `selection helpers` which allow you to match patterns or a condition. Read about them in the help for `select` in the Help window and try them out. 

## (2) filter
The filter function allows us to choose certain rows from the tibble, based on some sort of filtering criterion. Filter needs to know two things; The first is the name of the tibble, again, exp_data. The second is the filter parameter. The filter parameter is just a statement about the value of the column. You have the following basic options: 
(1) == means that the value must exactly equal the chosen value
(2) != means that the value can be anything but the chosen value (essentially (!)not (=)equal to)
(3) you can use < and <= for less than or less than or equal to
(4) and > >= for greater than and greater than or equal to. 

Let's look at some examples:

For example, in our data, we may want to know only about AAM data.

```{r}
filter(exp_data, Race == "AAM")
```

Can you use the %>% to do the same?

Maybe we only want samples (in rows) with normalized TPM2 expression at least 13

```{r}
filter(exp_data, TPM2 >= 13)
```
Again, there are several additional options that make this more powerful. Take a look at them in the Help window for `filter`.

## (3) mutate
The mutate function allows you to make a new column in your data frame which can be based on manipulation of existing ones. Mutate needs to know the name of the data frame you're taking data from and adding to, the name of the new column you're adding, and the value of that column.

For example, lets use mutate to log transform AZGP1 expression. 

```{r}
mutate(exp_data, AZGP1_log = log10(AZGP1))
```

The above is the same as 

```{r}
exp_data %>% mutate(AZGP1_log = log10(AZGP1))
```
Note: If you wanted to see the `AZGP1_log` column as the first column, you could use `select` on the output along with the helper `everything()`.

## (4) group_by
The group_by function allows you to group the rows based on the values in a particular column. For example, say you want to compare expression by risk group (CAPRAS score translated to low/intermediate/high)

```{r}
group_by(exp_data, CAPRASgroup)
```

The results of group_by aren't inherently useful, they don't reorder the table, but they add a layer of organization that can be used by other functions. In just a minute we'll start stacking these together to more interesting manipulations. 

## (5) summarize
The summarize function takes a tibble and summarizes it, but it won't summarize the whole thing; it needs you to group_by one of the variables and it will summarize each group--however you want to analyze them. So how do we stack two steps together? There's a symbol called a pipe, or %>%. This takes the output of one line, and sticks it into another function. 

Let's look at an example:

```{r}
exp_data %>%
  group_by(CAPRASgroup) %>%
  summarize(median(S1PR4))
```

So the pipe takes the data from line one, and sends it into the group_by function, where we add in the CAPRA-S group option to group by, and then takes the grouped data  and puts it into summarize, where we put in one more parameter, that we want to calculate the median expression of S1PR4. The output is the median of S1PR4 expression for each group. But usually we don't want just one function and one variable to be summarized. 

We can use summarize_at, and a list of functions to apply them on a few variables. 

```{r}
exp_data %>%
  group_by(CAPRASgroup) %>%
  summarize_at(vars(S1PR4, COL1A1,ANO7), list(apple=min, potato=mean, tomato=max))
```

# IV. Plotting your data:
So we got a ton of data, and we want to see what it looks like. ggplot2 is one such R package for making publication quality plots. 

What does ggplot2 need to know to make your plot?

The first step is to tell ggplot the name of the tibble your data is coming from, and you need to tell it the "aesthetics" you want, so tell it what you want along the x axis, and what you want on the y axis. Then we save that all to an object, which I called "g". Here's a sort of template for what that looks like:

g = ggplot("name of data frame here", aes("x variable column name here","y variable column name here"))

So what can we plot in our example data frame? We can see our options by viewing the column names of our data frame.
```{r}
colnames(exp_data)
```

Let's have ggplot make a plot of COL1A1 vs S1PR4 expression 

```{r}
g = ggplot(exp_data, aes(S1PR4,COL1A1))
```

So we typed that in, but what actually happened? Nothing came out in the console, but our g object did show up in our environment. Let's try to look at it.

```{r}
g 
```

Well that looks like the plot we want to make, but there's nothing on it. That's because we need to add something called a layer. So we have the ggplot function, with the aes inside that tells the program what the x and y axes should be, and then there's the "geom" component, and that is how we will indicate what we want the data to look like on the plot. And we've given you a cheat sheet for how to choose various types of "geoms". The options are ones you're familiar with, like geom_point will give you a scatter plot, and geom_boxplot will give you a box plot. Let's add a geom_point layer to our graph so we can see the data. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(S1PR4,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point()
### Finally, we look at the plot!
g
```

Now we can tell that there's a correlation between the the two genes. But what if we want to fit a line to this data, just to visualize the trend? We can add a layer called geom_smooth, just like geom_point, and looking at the plot, we can try to fit a linear model, so we tell geom_smooth that it should use method = lm, for linear model. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(S1PR4,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point() + geom_smooth(method = lm)
### Finally, we look at the plot!
g
```

Let's try it again, but this time with different variables. Let's look at the relationship between race and COL1A1 expression. Let's just plug it in to the last command we used. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_point()
### Finally, we look at the plot!
g
```

Well that's not quite what we want... Clearly the wrong geom. With one discrete variable and one continuous variable, we should plot this as a box_plot. 

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race, COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot()
### Finally, we look at the plot!
g
```

The boxplot is nice, but what if we want to know more about the specific data points, and also have our boxplot? Just add another layer to the plot.

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race, COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot() + geom_point()
### Finally, we look at the plot!
g
```

The boxplot looks nice, but we several data points overlap each other. Let's use another geom which should improve that

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race, COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot() + geom_jitter()
### Finally, we look at the plot!
g
```

Hmm, better, but look at the outliers. They seem repeated now. Let's fix that

```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race, COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot(outlier.shape=NA) + geom_jitter()
### Finally, we look at the plot!
g
```


Finally, let's clean up the labels, so everyone who looks at it knows what it represents!
```{r}
### We start again with the command, the data frame, and the two variables we want to plot.
g = ggplot(exp_data, aes(Race,COL1A1))
### Next, we add the geom layer, we just rename our object g as the first line + a geom layer
g = g + geom_boxplot(outlier.shape=NA) + geom_jitter()
### Next, let's change the axes
g = g + xlab("Sample Race") + ylab("COL1A1 expression")
### Finally, we look at the plot!
g
```
These are just some basic plots we can make using ggplots. and if you want to do more with your ggplot, the easiest way to figure out how to do it is to google what you want to do. For example, just type in "color the points by a certain column in ggplot2", or "changing the x and y axis titles in ggplot2". One of the top three hits will likely be an in depth tutorial that can help you build whatever plot you want. 


# V. Putting it all together

So let's play around with this dataset and try to answer some specific questions.

**Does the expression of COL1A1 differ based on race in the HIGH risk group?**

Ideally we would want to apply a statistical test to answer this question, but let us visualize the data first.

Let us break it down into steps:
 # start with our whole data frame  
 # filter out our results to get high CAPRA-S risk group (CAPRASgroup == "HIGH")  
 # now put COL1A1 expression on the y-axis, and the sample race on the x-axis
 # add the geom layer   
 # add axis labels   
```{r, echo=TRUE}
exp_data %>% 
  filter(CAPRASgroup == "HIGH") %>% 
  ggplot(aes(Race, COL1A1)) + 
  geom_boxplot(outlier.shape=NA) + 
  geom_jitter() +
  labs(x="Race", y="COL1A1 expression - High CAPRA-S")
```

Ok this is cool, but now can we apply a t-test to see if this is statistically significant?

```{r}
df <- exp_data %>% 
  filter(CAPRASgroup == "HIGH") %>%
  select(Race, COL1A1)
x <- (df %>% filter(Race == "EAM"))$COL1A1
y <- (df %>% filter(Race == "AAM"))$COL1A1
t.test(x,y)
```


All right, so let's ask a broader question

**Does the expression of COL1A1 differ based on race in the various groups?**

So here, we want to ask the same question as above, but compare all CAPRA-S groups at the same time. For plotting, we can use facets. Facets allow us to form panels in our plots.
In the following example, we supply CAPRA-S groups as variables for faceting. Each facet will display the data for one CAPRA-S group "variable"


```{r}
exp_data %>% 
  ggplot(aes(Race, COL1A1)) + 
  geom_boxplot(outlier.shape=NA) + 
  geom_jitter() +
  facet_grid(cols = vars(CAPRASgroup))+
  labs(x="Race", y="COL1A1 expression - CAPRA-S")
```

Let's do this so we can apply the t.test to all the groups simultaneously. Here we will learn another strategy, which is very useful. The idea is to nest based on groups and apply functions on each group. Let me explain in more detail

```{r}
exp_data %>%
  select(Race, CAPRASgroup, COL1A1) %>%
  group_by(CAPRASgroup) %>%
  nest()
```

So we have converted the data corresponding to each CAPRA-S group into a tibble. Now, similar to what we had done for the high-risk group, we can create a function which does that for any group given to it as input

```{r}
apply_t_test <- function(tbl) {
  x <- tbl %>% filter(Race == "AAM")
  y <- tbl %>% filter(Race == "EAM")
  t <- t.test(x$COL1A1, y$COL1A1)
  return(t$p.value)
}

exp_data %>% 
  select(Race, CAPRASgroup, COL1A1) %>%
  group_by(CAPRASgroup) %>%
  nest() %>%
  mutate(pvalue = map(data, apply_t_test)) %>%
  select(-data) %>%
  unnest() 
```

All right, so lets try to answer the real question.
**Which genes show difference in expression based on race in the various groups?** 

Let us build on the analyses we ran for COL1A1. Here we will convert the data from wide format to long format, so we can utilize all we have learnt so far
```{r}
exp_data %>%
  gather(gene, expression, -ID, -Race, -CAPRASgroup) %>%
  select(-ID)
```
```{r}
apply_t_test <- function(tbl) {
  x <- tbl %>% filter(Race == "AAM")
  y <- tbl %>% filter(Race == "EAM")
  t <- t.test(x$expression, y$expression)
  return(t$p.value)
}

exp_data %>% 
  gather(gene, expression, -ID, -Race, -CAPRASgroup) %>%
  select(-ID) %>%
  group_by(CAPRASgroup, gene) %>%
  nest() %>%
  mutate(pvalue = map(data, apply_t_test)) %>%
  select(-data) %>%
  unnest() 
```

Which of these are significant (p-value) < 0.05

```{r}
apply_t_test <- function(tbl) {
  x <- tbl %>% filter(Race == "AAM")
  y <- tbl %>% filter(Race == "EAM")
  t <- t.test(x$expression, y$expression)
  return(t$p.value)
}

exp_data %>% 
  gather(gene, expression, -ID, -Race, -CAPRASgroup) %>%
  select(-ID) %>%
  group_by(CAPRASgroup, gene) %>%
  nest() %>%
  mutate(pvalue = map(data, apply_t_test)) %>%
  select(-data) %>%
  unnest() %>%
  filter(pvalue < 0.05) %>%
  arrange(pvalue)
```

If you want to explore more of the options you have with ggplot2, refer to the cheat sheet we distributed as well. You can also always find that sheet by googling ggplot2 cheat sheet. 

I hope this tutorial was a helpful introduction to RStudio, dplyr, and ggplots. If you want to learn more, there are a lot of classes available from the Stat Lab and Bioconnector at the Health Science Library. All of these resources take what we just presented and help you to build on them.

## RESOURCES

### R Studio Online Learning
https://www.rstudio.com/online-learning/

### R Programming
Efficient R programming (https://csgillespie.github.io/efficientR/index.html)

### Tidyverse 
https://r4ds.had.co.nz/

### STATLAB COURSES
http://data.library.virginia.edu/training/

### STATISTICS RESOURCE
An Introduction to Statistical Learning
https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf


## CONTACT INFO

Dr. Aakrosh Ratan
ratan at virginia dot edu
